{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6715952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/PERSONALE/nicolas.biondini2/Interactomes/Sliding_hole_removal'\n",
    "\n",
    "d_dist_df_list = [[]]*len(os.listdir(base_path))\n",
    "i = 0\n",
    "\n",
    "for directory in os.listdir(base_path):\n",
    "    \n",
    "    path = os.path.join(base_path, directory)\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        if file.startswith('removal'):\n",
    "            df_path = os.path.join(path, file)\n",
    "        elif file.startswith('genes'):\n",
    "            nodes_list_path = os.path.join(path, file)\n",
    "\n",
    "\n",
    "    nodes_df = pd.read_csv(nodes_list_path)\n",
    "    d_dist_df_list[i] = pd.read_csv(df_path)    \n",
    "    d_dist_df_list[i]['nodes'] = pd.Series(dtype=\"object\")\n",
    "    \n",
    "    # Crea una mappatura da Posizione a Gene\n",
    "    mapping = dict(zip(nodes_df['Posizione'], nodes_df['Gene']))\n",
    "    # Usa la mappatura per assegnare la colonna 'Nodes_Removed'\n",
    "    d_dist_df_list[i]['nodes'] = d_dist_df_list[i].index.map(mapping)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "\n",
    "#creo il DF con le aree\n",
    "d_dist_areas_df = pd.DataFrame(index = range (len(os.listdir (base_path) )), columns = ['Area', 'Nodes_removed', 'Position'] )\n",
    "i = 0\n",
    "\n",
    "for df in d_dist_df_list:\n",
    "    d_dist_areas_df.at[i, 'Nodes_removed'] = df['nodes'].dropna().tolist()\n",
    "    d_dist_areas_df.at[i, 'Position'] = int(df[df['nodes'].notna()].index.tolist()[0])\n",
    "    d_dist_areas_df.at[i, 'Area'] = integrate.simpson(df['S'] , df['f'])\n",
    "    i += 1\n",
    "\n",
    "#calcolo la resilienza\n",
    "d_dist_areas_df['Resilience'] = 0.5 - d_dist_areas_df['Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert Ensembl IDs to HGNC symbols using mygene.info and Ensembl REST API\n",
    "\n",
    "import gseapy as gp\n",
    "import mygene\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def convert_ensembl_to_hgnc(ensembl_ids, verbose=False):\n",
    "    \"\"\"\n",
    "    Convert a list of Ensembl gene IDs to HGNC symbols using mygene.info and Ensembl REST API.\n",
    "    Args:\n",
    "        ensembl_ids (list): List of Ensembl gene IDs to convert.\n",
    "        verbose (bool): If True, print progress messages.\n",
    "    Returns:\n",
    "        dict: A dictionary mapping Ensembl IDs to HGNC symbols.\n",
    "    \"\"\"\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    converted = {}\n",
    "\n",
    "    # Primo tentativo: mygene.info\n",
    "    if verbose: print(\"ðŸ” Provo con mygene.info...\")\n",
    "    results = mg.querymany(\n",
    "        ensembl_ids,\n",
    "        scopes='ensembl.gene',\n",
    "        fields='symbol',\n",
    "        species='human',\n",
    "        as_dataframe=False\n",
    "    )\n",
    "\n",
    "    not_found = []\n",
    "\n",
    "    for r in results:\n",
    "        ensg = r['query']\n",
    "        if 'symbol' in r:\n",
    "            converted[ensg] = r['symbol']\n",
    "        else:\n",
    "            not_found.append(ensg)\n",
    "            if verbose: print(f\"âŒ Non trovato in mygene: {ensg}\")\n",
    "\n",
    "    # Secondo tentativo: Ensembl REST API\n",
    "    if verbose: print(\"ðŸ”„ Provo con Ensembl REST API per quelli mancanti...\")\n",
    "    for ensg in not_found:\n",
    "        url = f\"https://rest.ensembl.org/xrefs/id/{ensg}?content-type=application/json;external_db=HGNC\"\n",
    "        r = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n",
    "        if r.ok:\n",
    "            data = r.json()\n",
    "            if data:\n",
    "                symbol = data[0]['display_id']\n",
    "                converted[ensg] = symbol\n",
    "                if verbose: print(f\"âœ… Trovato via Ensembl: {ensg} â†’ {symbol}\")\n",
    "            else:\n",
    "                if verbose: print(f\"âŒ Ancora non trovato: {ensg}\")\n",
    "        else:\n",
    "            if verbose: print(f\"âš ï¸ Errore con Ensembl API per {ensg}: {r.status_code}\")\n",
    "        time.sleep(0.1)  # rate limiting\n",
    "\n",
    "    return converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3790597",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enrichment Analysis ###\n",
    "\n",
    "\n",
    "def gene_enrichment_analysis(gene_list, gene_set=['GO_Biological_Process_2025'], organism='Human'):\n",
    "    \"\"\"\n",
    "    Esegue l'analisi di arricchimento dei geni utilizzando Enrichr.\n",
    "    Args:\n",
    "        gene_list (list): Lista di geni da analizzare.\n",
    "    Returns:\n",
    "        pd.DataFrame: Risultati dell'analisi di arricchimento.\n",
    "    \"\"\"\n",
    "\n",
    "    import gseapy as gp\n",
    "\n",
    "    enr = gp.enrichr(\n",
    "        gene_list=gene_list,\n",
    "        gene_sets = gene_set,\n",
    "        organism = organism,\n",
    "        outdir=None,  # Non salvare su disco\n",
    "        cutoff=0.05\n",
    "    )\n",
    "    return enr.results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc427df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TROVO IL VALORE DI TAGLIO PER d_dist_areas_hugo_df\n",
    "\n",
    "# Estrai i dati di resilience\n",
    "resilience_data = d_dist_areas_hugo_df['Resilience'].dropna().astype(float).values\n",
    "\n",
    "# Calcola l'istogramma con 1000 bin\n",
    "counts, bin_edges = np.histogram(resilience_data, bins=1000)\n",
    "\n",
    "# Trova i bin che corrispondono all'intervallo richiesto\n",
    "mask_bins = (bin_edges[:-1] >= 0.45225) & (bin_edges[1:] <= 0.45233) #intervallo scelto \"a vista\" dal grafico. Il punto di minimo Ã¨ lÃ¬ dentro\n",
    "\n",
    "# Seleziona i conteggi e i centri dei bin nell'intervallo\n",
    "selected_counts = counts[mask_bins]\n",
    "selected_bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "selected_bin_centers = selected_bin_centers[mask_bins]\n",
    "\n",
    "# Trova il valore di resilience meno popoloso nell'intervallo\n",
    "if len(selected_counts) > 0:\n",
    "    idx_min = np.argmin(selected_counts)\n",
    "    min_resilience = selected_bin_centers[idx_min]\n",
    "    min_count = selected_counts[idx_min]\n",
    "    print(f\"Valore di resilience meno popoloso: {min_resilience}, conteggio: {min_count}\")\n",
    "else:\n",
    "    print(\"Nessun bin trovato nell'intervallo specificato.\")\n",
    "\n",
    "\n",
    "cut_value = 0.4523077770321452 #valore trovato con il metodo sopra\n",
    "\n",
    "#seleziono i geni con resilience maggiore del cut_value\n",
    "mask = (d_dist_areas_df['Resilience'].astype(float) >= cut_value)   \n",
    "\n",
    "genes_of_interest = d_dist_areas_df[mask].dropna()['Nodes_removed'].explode().dropna().unique().tolist()\n",
    "\n",
    "\n",
    "# Converti gli Ensembl IDs in HGNC symbols\n",
    "gene_symbols = list( convert_ensembl_to_hgnc(genes_of_interest, verbose=True).values() )\n",
    "\n",
    "# Esegui l'analisi di arricchimento\n",
    "peak_enr = gene_enrichment_analysis(gene_symbols, gene_set=['GO_Biological_Process_2025'], organism='Human')\n",
    "\n",
    "#save the significant results\n",
    "peak_enr.loc[peak_enr['Adjusted P-value'] < 0.05].sort_values(by='Adjusted P-value').to_csv('db2020_peak_enrichment.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
